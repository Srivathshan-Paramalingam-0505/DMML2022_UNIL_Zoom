{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY3SEbvKGI8p"
      },
      "source": [
        "### Context\n",
        "\n",
        "For text classification with difficulty, we are going to train our model with the logistic regression classification. But, we are going to set different parameters to define which model give the best accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L8x8s7T2GEK6"
      },
      "outputs": [],
      "source": [
        "#Import the packages we need\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn. preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAQelL8nGqH7",
        "outputId": "449abd9c-cf23-4514-9c7a-32bc15c91a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Load the dataset using google drive mount (inspired by the challenge notebook)\n",
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw7-3DZPG3AU",
        "outputId": "060ec655-bf2b-4c46-ab99-f1c6d96744fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "# install Kaggle\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgNmxFW8G6rj",
        "outputId": "80ea1f5c-3fa1-45d6-cecf-f96b69bd4f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#read in your Kaggle credentials from Google Drive\n",
        "!cp /content/drive/MyDrive/Coding_Challenge/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKG4cO4nG8Jc",
        "outputId": "3f0c76c7-4616-4248-e060-b7fa2a180328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "# download the dataset from the competition page\n",
        "! kaggle competitions download -c detecting-french-texts-difficulty-level-2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C2lIqZhiHHFA"
      },
      "outputs": [],
      "source": [
        "#let's load the dataset\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/Coding_Challenge/training_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.read_csv('drive/MyDrive/Coding_Challenge/unlabelled_test_data.csv')"
      ],
      "metadata": {
        "id": "g0l4ckgbfAl9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Kwpx6lBeHUND"
      },
      "outputs": [],
      "source": [
        "#splitting the data\n",
        "X = df['sentence']\n",
        "y = df['difficulty']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7iNF3TMhHa5F"
      },
      "outputs": [],
      "source": [
        "#Define a model AND apply vectorizer\n",
        "LR = LogisticRegression(penalty='l2', dual=False, tol=0.001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=1000, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO1iTyStIBHU",
        "outputId": "18d6ca55-d125-4e3d-bdc1-6f227a9bd2c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(max_iter=1000, solver='newton-cg',\n",
              "                                    tol=0.001))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Using default tokenizer in TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(ngram_range=(1,1))\n",
        "# Create a pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', LR)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dqGmr5FEIFWi"
      },
      "outputs": [],
      "source": [
        "#function to calculate metrics of the models\n",
        "def models_metrics (true, pred):\n",
        "  precision = precision_score(true, pred, average='weighted')\n",
        "  recall = recall_score(true, pred, average='weighted')\n",
        "  f1 = f1_score(true, pred, average='weighted')\n",
        "  print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred,)}\")\n",
        "  print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "  print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "24ap7CZaILBr"
      },
      "outputs": [],
      "source": [
        "#predict on test split\n",
        "y_pred_lr = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTL6ZuGYIQOm",
        "outputId": "17abdf7c-fb67-4611-ab3e-fdf08f700c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[93 31 21 10  4  2]\n",
            " [54 60 30  6  6  8]\n",
            " [12 38 64 17  9 20]\n",
            " [ 6  6 15 66 27 24]\n",
            " [ 4  4 10 37 73 45]\n",
            " [ 7  8  8 19 24 92]]\n",
            "ACCURACY SCORE:\n",
            "0.4667\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4656\n",
            "\tRecall: 0.4667\n",
            "\tF1_Score: 0.4640\n"
          ]
        }
      ],
      "source": [
        "#get the metrics\n",
        "models_metrics(y_test,y_pred_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are going to try different tokenization method, with different models"
      ],
      "metadata": {
        "id": "NnIKhcvjsUO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "ePtxnRzOsa4l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDTWzUPMo7T",
        "outputId": "ae086a1a-8308-47c7-f4e0-4ee6c4744ccd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import from NLTK"
      ],
      "metadata": {
        "id": "pxMglyY11bRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re"
      ],
      "metadata": {
        "id": "1rzbtRcA1avh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "French language"
      ],
      "metadata": {
        "id": "LI8H3_8x1gfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "french_stopwords = set(stopwords.words('french'))\n",
        "filtre_stopfr =  lambda text: [token for token in text if token.lower() not in french_stopwords]"
      ],
      "metadata": {
        "id": "Z7q-6A5a1sJ8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtre_stopfr( word_tokenize(X.loc[0], language=\"french\") )"
      ],
      "metadata": {
        "id": "KjuXmS-S21AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0737b7e6-020f-4a3c-a805-9468e3ba2de2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coûts',\n",
              " 'kilométriques',\n",
              " 'réels',\n",
              " 'peuvent',\n",
              " 'diverger',\n",
              " 'sensiblement',\n",
              " 'valeurs',\n",
              " 'moyennes',\n",
              " 'fonction',\n",
              " 'moyen',\n",
              " 'transport',\n",
              " 'utilisé',\n",
              " ',',\n",
              " 'taux',\n",
              " \"d'occupation\",\n",
              " 'taux',\n",
              " 'remplissage',\n",
              " ',',\n",
              " \"l'infrastructure\",\n",
              " 'utilisée',\n",
              " ',',\n",
              " 'topographie',\n",
              " 'lignes',\n",
              " ',',\n",
              " 'flux',\n",
              " 'trafic',\n",
              " ',',\n",
              " 'etc',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp_pattern = re.compile( \"\"\"[\\.\\!\\\"\\s\\?\\-\\,\\']+\"\"\", re.M).split\n",
        "sp_pattern(X.loc[25])"
      ],
      "metadata": {
        "id": "L3VUjVwh9HUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be984f4f-a3dc-47f8-b472-4a13306fbd19"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Qu',\n",
              " 'est',\n",
              " 'ce',\n",
              " 'qui',\n",
              " 'peut',\n",
              " 'bien',\n",
              " 'poser',\n",
              " 'problème',\n",
              " 'dans',\n",
              " 'ces',\n",
              " 'petits',\n",
              " 'livrets',\n",
              " 'pourtant',\n",
              " 'plutôt',\n",
              " 'attractifs',\n",
              " 'pour',\n",
              " 'que',\n",
              " 'seuls',\n",
              " '23',\n",
              " '4',\n",
              " '%',\n",
              " 'de',\n",
              " 'leurs',\n",
              " 'détenteurs',\n",
              " 'arrivent',\n",
              " 'au',\n",
              " 'bout',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def last_test (data):\n",
        "  data = re.sub(\" \\d+\", \" \", data)\n",
        "  data = sp_pattern(data)\n",
        "  return data\n",
        "last_test(X.loc[25])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzjtTjJec2ks",
        "outputId": "5e1888d4-c936-48d3-944e-c61ec7c1254f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Qu',\n",
              " 'est',\n",
              " 'ce',\n",
              " 'qui',\n",
              " 'peut',\n",
              " 'bien',\n",
              " 'poser',\n",
              " 'problème',\n",
              " 'dans',\n",
              " 'ces',\n",
              " 'petits',\n",
              " 'livrets',\n",
              " 'pourtant',\n",
              " 'plutôt',\n",
              " 'attractifs',\n",
              " 'pour',\n",
              " 'que',\n",
              " 'seuls',\n",
              " '%',\n",
              " 'de',\n",
              " 'leurs',\n",
              " 'détenteurs',\n",
              " 'arrivent',\n",
              " 'au',\n",
              " 'bout',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data (data): #stopwords and re.compile combined, less effective with stopwords\n",
        "  cleaned_data = sp_pattern (data)\n",
        "  cleaned_data = filtre_stopfr(cleaned_data)\n",
        "  return cleaned_data"
      ],
      "metadata": {
        "id": "oefzvXeeRLWe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data(X.loc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujt2ShppRewG",
        "outputId": "7c6672d1-d9b3-46d3-a2f5-a08089a36a44"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coûts',\n",
              " 'kilométriques',\n",
              " 'réels',\n",
              " 'peuvent',\n",
              " 'diverger',\n",
              " 'sensiblement',\n",
              " 'valeurs',\n",
              " 'moyennes',\n",
              " 'fonction',\n",
              " 'moyen',\n",
              " 'transport',\n",
              " 'utilisé',\n",
              " 'taux',\n",
              " 'occupation',\n",
              " 'taux',\n",
              " 'remplissage',\n",
              " 'infrastructure',\n",
              " 'utilisée',\n",
              " 'topographie',\n",
              " 'lignes',\n",
              " 'flux',\n",
              " 'trafic',\n",
              " 'etc',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to try this tokenization method with the different models"
      ],
      "metadata": {
        "id": "TknOazlA31zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,1))"
      ],
      "metadata": {
        "id": "fjHqfnlZJEFc"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer= sp_pattern, ngram_range=(1,1))"
      ],
      "metadata": {
        "id": "G4B7ZjZh3hmw"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Randfor=RandomForestClassifier(n_estimators=500)"
      ],
      "metadata": {
        "id": "o_KBI27b5rt_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', Randfor)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-l9OaaNk55GP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfeb6a2-6b14-4589-a328-834d013405d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<built-in method split of re.Pattern object at 0x7f36d6970d30>)),\n",
              "                ('classifier', RandomForestClassifier(n_estimators=500))])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_randfor=pipe.predict(X_test)"
      ],
      "metadata": {
        "id": "XYweNuH17Gm-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate metrics of the models\n",
        "def models_metrics (true, pred):\n",
        "  precision = precision_score(true, pred, average='weighted')\n",
        "  recall = recall_score(true, pred, average='weighted')\n",
        "  f1 = f1_score(true, pred, average='weighted')\n",
        "  print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred,)}\")\n",
        "  print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "  print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "HAkzm3j27Q4x"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_metrics(y_test, y_pred_randfor)"
      ],
      "metadata": {
        "id": "dGVmEeqO7Wer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833840dd-f369-4204-989c-8ff56122587c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[122  17  14   7   1   0]\n",
            " [ 68  57  27   8   3   1]\n",
            " [ 24  35  65  26   6   4]\n",
            " [  8  11  20  65  29  11]\n",
            " [ 16   8  22  53  46  28]\n",
            " [ 12  10  12  26  26  72]]\n",
            "ACCURACY SCORE:\n",
            "0.4448\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4497\n",
            "\tRecall: 0.4448\n",
            "\tF1_Score: 0.4359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with the Logistic Regression"
      ],
      "metadata": {
        "id": "aiIxk4GV8Bxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_lr = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', LR)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_lr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "5NxaB_os8Ewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f992be-a093-4b14-aa39-08123e37baa0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<built-in method split of re.Pattern object at 0x7f36d6970d30>)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(max_iter=1000, solver='newton-cg',\n",
              "                                    tol=0.001))])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lr2=pipe_lr.predict(X_test)"
      ],
      "metadata": {
        "id": "jfyO1NQG8tVr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_metrics(y_test,y_pred_lr2)"
      ],
      "metadata": {
        "id": "vZ9pR3rI80vy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869bcbc9-03e6-4c5a-9563-7fc038ed534f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[101  32  15   7   3   3]\n",
            " [ 55  60  32   5   7   5]\n",
            " [ 10  39  71  16   9  15]\n",
            " [  7   5  17  69  26  20]\n",
            " [  3   3  13  37  70  47]\n",
            " [  5   3   9  19  20 102]]\n",
            "ACCURACY SCORE:\n",
            "0.4927\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4897\n",
            "\tRecall: 0.4927\n",
            "\tF1_Score: 0.4882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Now with the SVC classifier"
      ],
      "metadata": {
        "id": "BHJ_rLb32Z6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC(gamma=\"scale\", random_state=42,kernel = 'poly', coef0 = 0.5)"
      ],
      "metadata": {
        "id": "SXFbjihd2v3W"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_svc = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', svc)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_svc.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW5qjKkQ2sLg",
        "outputId": "872acb63-bfa2-4a57-865b-73dfbcf6addc"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<built-in method split of re.Pattern object at 0x7f36d6970d30>)),\n",
              "                ('classifier', SVC(coef0=0.5, kernel='poly', random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_svc=pipe_svc.predict(X_test)"
      ],
      "metadata": {
        "id": "OSkExnUT24Ep"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_metrics(y_test,y_pred_svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzV5b_wR3TIC",
        "outputId": "cb4311ee-5837-4b86-9400-cfb0cefec70f"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[99 32 19  6  3  2]\n",
            " [43 71 32  7  6  5]\n",
            " [ 6 38 79 17  9 11]\n",
            " [ 3  9 18 70 24 20]\n",
            " [ 2  2 13 45 65 46]\n",
            " [ 3  7  9 19 21 99]]\n",
            "ACCURACY SCORE:\n",
            "0.5031\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.5047\n",
            "\tRecall: 0.5031\n",
            "\tF1_Score: 0.5012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color = 'red'>Code to submit"
      ],
      "metadata": {
        "id": "3KxpOpbq3DGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred_submit_svc = df_pred.copy()"
      ],
      "metadata": {
        "id": "W-maqMJKe4d6"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabelled_svc=pipe_svc.predict(df_pred_submit_svc['sentence'])\n",
        "unlabelled_svc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxRi2D5rfGuc",
        "outputId": "f56afb0b-abdc-4dd4-e420-febf5a78696b"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['C2', 'B1', 'A1', ..., 'C2', 'B2', 'B1'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred_submit_svc['difficulty']=unlabelled_svc #to modify when using another classification model\n",
        "df_pred_submit_svc =df_pred_submit_svc.drop('sentence',axis=1)"
      ],
      "metadata": {
        "id": "rWD-OfWTfcQv"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for the submission part: \n",
        "from google.colab import files\n",
        "df_pred_submit_svc.to_csv('teamzoom_submit_svc.csv', encoding ='utf-8-sig',index=False) \n",
        "files.download('teamzoom_submit_svc.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JWgh9WWFfj1e",
        "outputId": "3ae1e141-0471-41dc-b155-73b4bce9ba60"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_83816256-4100-4214-8b53-3921854ed7ea\", \"teamzoom_submit_svc.csv\", 8507)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}