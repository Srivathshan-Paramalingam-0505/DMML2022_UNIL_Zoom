# Team_zoom_coding_challenge - Training a model to compute french difficulty
*This is our way of resolving the coding challenge!*
## Summary
* Provided data
* First notebook : Project guidelines
* Second notebook : Different tokenizers
* Third notebook : Text classification using NTLK (natural language toolkit)
* References

## Provided data
## First notebook : Project guidelines
On that part, we trained models using our raw data, without cleaning them
## Second notebook : Different tokenizers
On that notebook, we tried to tokenize using several ways, particularly with the following libraries : regular expression (re) and spacy tokenizer
## Third notebook : Text classification using NTLK (natural language toolkit)
On that last part, we decided to create a new DataFrame containing new features about the properties of the sentences. Once cleaned, we used the ntlk library to clean the data before training them in our models.
## References

### Main reference: 
* https://scikit-learn.org/stable/index.html
### Reference for the feature extraction
* https://docs.python.org/3/howto/regex.html
* https://towardsdatascience.com/ensemble-methods-or-democracy-for-ai-bac2fa129f61
* https://datacorner.fr/nltk/
